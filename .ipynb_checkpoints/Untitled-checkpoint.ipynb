{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK FUNDAMENTALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THINGS THAT WILL BE TALKED IN THIS NOTEBOOK ARE:\n",
    "* what is neural network?\n",
    "* weights and biases in neural network\n",
    "* activation function\n",
    "* backward propagation\n",
    "* why it neural network is being adopted extensively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network  is a set  of neurons interconnected together and when fired up in a certain pattern results a certian output. Neural network is a model inspired from a biological neurons of human beings. It can be a complex system because number of input neurons depends on dimension of input vectors. As well as there can be number of hidden layer networks with plenty of neurons in it. Aslo some value of parameters must be assigned for each interconnected neurons that makes overall huge number of parameters that governs a output of neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.google.com/imgres?imgurl=https%3A%2F%2Fwww.apple.com%2Fac%2Fstructured-data%2Fimages%2Fknowledge_graph_logo.png%3F202108131106&imgrefurl=https%3A%2F%2Fwww.apple.com%2Fiphone%2F&tbnid=-TtEc9M5pE7LPM&vet=12ahUKEwixutDOzb7yAhWeCrcAHZaIBSUQMygAegUIARDPAQ..i&docid=JIjFa1byZv7Q7M&w=302&h=302&q=apple&ved=2ahUKEwixutDOzb7yAhWeCrcAHZaIBSUQMygAegUIARDPAQ\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights and Biases in Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weights and biases are the parameters which are responsible for fine tuneing the neural network to achieve the desired output. If there are n input neurons and m neurons connected to these than there will be [m*n] weights and one biase. Each weight defines the level of importance of that neuron to produce an output. \n",
    "\n",
    "let input be a vector of 3 dimension  [X] = [\n",
    "                                             x1\n",
    "                                             x2\n",
    "                                             x3\n",
    "                                             ]\n",
    "                                         \n",
    "so, dimension of weights will be  [W] =   w11  w21  w31\n",
    "\n",
    "                                           w12  w22  w32\n",
    "                                        \n",
    "                                           w13  w23  w33\n",
    "\n",
    "let bias [B] = b\n",
    "                                        \n",
    "let hidden layer be of 3 neurons \n",
    "\n",
    "than output at each neuron = [W] * [X] *[B] = \n",
    "                                                x1*w11 + x2*w21 + x3*w31 + b\n",
    "                                           \n",
    "                                                x1*w12 + x2*w22 + x3*w32 + b \n",
    "                                           \n",
    "                                                x1*w13 + x2*w23 + x3*w33 + b\n",
    "                                                \n",
    "#### This method of calcuation is called forward-pass.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When value of neuron is calcuated by adding weights and biases to each input , the value thus obtained will be linear in nature since we have used linear formula like 'mx+c'. But we need the output of neuron to be value which defines if that neuron will fire or not. To achieve this we should impose non-linear function like sigmoid, tanh relu etc. These function are called activation function which help us to obtain non linearity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calcuating final output, the output value is compared with the given label of output which is the true output for this input. And than we calcuate the deviation of our output with required output which is called loss. If there is multiple number of outputs required than we calcuate cost value by averaging each loss value. Generally loss is taken as squared error. By whole effort will be to miminize the loss function. For that purpose ,we know adjust the each weight value according to the cost function value. This is called backward propagation.\n",
    "\n",
    "#### Same process of forward and backward propagation will be continued for number of iterations untill the cost value is minimized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Neural Network is being Adopted Extensively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network was introduced in 80's era but its application decreased in late 90's. And again it is gaining its hike nowadays because it can be used to solve complex problems. The fundamentals of neural network is data. More data we fed to it, more robust the network will be. But in past, there was scracity of data and at present due to age of digitilazition,  huge amount of data is avaliable. And also computational ability of computers has been improved to a greater extent which has helped us to break the constraint of computational power. Thus Neural network is gaining popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
